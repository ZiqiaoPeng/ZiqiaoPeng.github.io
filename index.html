<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Ziqiao Peng - Academic Homepage</title>
  <meta name="author" content="Ziqiao Peng">
  <meta name="description" content="Ziqiao Peng's academic homepage - Research on Generative AI and Digital Humans, focusing on audio-driven talking avatar synthesis, lip synchronization, and real-time interactive avatars.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üéì</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <!-- Profile Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name><span style="font-family: 'Times New Roman', Times, serif;">Ziqiao Peng</span> <span style="font-family: 'KaiTi', 'STKaiti', 'AR PL UKai CN', serif;">ÂΩ≠Â≠ê‰πî</span></name>
                  </p>
                  <p style="margin-top:16px;">
                    I am a fourth-year PhD candidate at 
                    <a href="https://www.ruc.edu.cn/en">Renmin University of China</a>,
                    supervised by <a href="http://info.ruc.edu.cn/jsky/rtjs/d696a551fefc4b0ab6f90e02b01f3529.htm">Prof. Jun He</a> from Renmin University of China and <a href="https://www.sem.tsinghua.edu.cn/info/1189/32080.htm">Prof. Hongyan Liu</a> from Tsinghua University.
                  </p>
                  <p style="margin-top:12px;">
                    My research focuses on <strong>Generative AI</strong> and <strong>Digital Humans</strong>, with a focus on audio-driven talking avatar synthesis, lip synchronization, and real-time interactive avatars.
                  </p>
                  <p style="margin-top:12px; padding:12px 16px; background:linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border-radius:8px; font-size:14px;">
                    üéì I am expected to graduate in <strong>June 2027</strong> and actively seeking <strong>full-time positions</strong> in China and abroad. Feel free to reach out!<br>ÊàëÈ¢ÑËÆ°‰∫é<strong>2027Âπ¥6Êúà</strong>ÊØï‰∏öÔºåÊ≠£Âú®ÂØªÊâæ<strong>ÂõΩÂÜÖÂ§ñÂÖ®ËÅåÂ∑•‰ΩúÊú∫‰ºö</strong>ÔºåÊ¨¢ËøéËÅîÁ≥ªÔºÅ
                  </p>
                  <div class="links-row" style="justify-content:center;margin-top:16px;">
                    <a href="mailto:pengziqiao@ruc.edu.cn"><i class="fas fa-envelope"></i> Email</a>
                    <a href="https://github.com/ZiqiaoPeng" target="_blank"><i class="fab fa-github"></i> GitHub <span style="background:#fef3c7;color:#92400e;padding:2px 6px;border-radius:4px;font-size:12px;margin-left:4px;">‚≠ê 2.3k+</span></a>
                    <a href="https://scholar.google.com/citations?user=gYTyZGYAAAAJ" target="_blank"><i class="fas fa-graduation-cap"></i> Scholar</a>
                    <div class="wechat-wrapper" style="display:inline-block;position:relative;">
                      <a href="javascript:void(0)" onclick="toggleWechatQR()" id="wechat-link"><i class="fab fa-weixin"></i> WeChat</a>
                      <div id="wechat-qr-popup" style="display:none;position:absolute;top:100%;left:50%;transform:translateX(-50%);margin-top:10px;background:white;padding:10px;border-radius:8px;box-shadow:0 4px 12px rgba(0,0,0,0.15);z-index:100;">
                        <img src="images/wechat-qr.jpg" style="width:200px;height:auto;border-radius:4px;">
                      </div>
                    </div>
                  </div>
                </td>
                <td style="padding:2.5%;width:35%;max-width:35%">
                  <a href="images/ZiqiaoPeng.jpg">
                    <img class="profile-photo" style="width:100%;max-width:100%" alt="Ziqiao Peng" src="images/ZiqiaoPeng.jpg">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- News Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading><i class="fas fa-newspaper" style="margin-right:8px;color:#2563eb;"></i>News</heading>
                  <div class="news-section" style="margin-top:20px;">
                    <div class="news-item">
                      <span class="news-date">2025.11</span>
                      <div class="news-content">
                        <span class="news-tag paper">Journal</span>
                        <strong>SyncTalk++</strong> accepted to <strong>IEEE TPAMI</strong>!
                      </div>
                    </div>
                    <div class="news-item">
                      <span class="news-date">2025.09</span>
                      <div class="news-content" style="display:flex;align-items:center;gap:8px;">
                        <span class="news-tag spotlight" style="margin-right:0;">Spotlight</span>
                        <div>
                          <strong>OmniSync</strong> accepted to <strong>NeurIPS 2025</strong> as Spotlight!<br>
                          <a href="https://papercopilot.com/paper-list/neurips-paper-list/neurips-2025-paper-list/" target="_blank"><strong>Ranked 3rd</strong></a> among all NeurIPS 2025 papers üèÜ
                        </div>
                      </div>
                    </div>
                    <div class="news-item">
                      <span class="news-date">2025.09</span>
                      <div class="news-content">
                        <span class="news-tag new">New</span>
                        <strong>MEGADance</strong> accepted to <strong>NeurIPS 2025</strong>!
                      </div>
                    </div>
                    <div class="news-item">
                      <span class="news-date">2025.06</span>
                      <div class="news-content">
                        <span class="news-tag spotlight">Spotlight</span>
                        <strong>GGTalker</strong> accepted to <strong>ICCV 2025</strong> as Spotlight!
                      </div>
                    </div>
                    <div class="news-item">
                      <span class="news-date">2025.04</span>
                      <div class="news-content">
                        <span class="news-tag new">New</span>
                        <strong>Morpheus</strong> accepted to <strong>RSS 2025</strong>!
                      </div>
                    </div>
                    <div class="news-item">
                      <span class="news-date">2025.03</span>
                      <div class="news-content">
                        <span class="news-tag new">New</span>
                        <strong>DualTalk</strong> accepted to <strong>CVPR 2025</strong>!
                      </div>
                    </div>
                    <div class="news-item">
                      <span class="news-date">2024.02</span>
                      <div class="news-content">
                        <span class="news-tag new">New</span>
                        <strong>SyncTalk</strong> accepted to <strong>CVPR 2024</strong>!
                      </div>
                    </div>
                  </div>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Experience Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading><i class="fas fa-briefcase" style="margin-right:8px;color:#2563eb;"></i>Experience</heading>
                  <div class="experience-section" style="margin-top:20px;">
                    
                    <div class="experience-item" style="display:flex;align-items:center;margin-bottom:16px;padding:16px;background:#f8fafc;border-radius:8px;border-left:3px solid #2563eb;">
                      <img src="images/logos/heygen.png" alt="HeyGen" style="width:40px;height:40px;object-fit:contain;margin-right:16px;border-radius:8px;">
                      <div style="flex:1;">
                        <div style="font-weight:600;color:#1e293b;">HeyGen ‚Äî AI Research Team</div>
                        <div style="font-size:13px;color:#64748b;margin-top:4px;">Research Intern ¬∑ Multimodal Video Generation & Real-Time Streaming</div>
                      </div>
                      <div style="font-size:13px;color:#64748b;white-space:nowrap;">Dec 2025 - Present</div>
                    </div>

                    <div class="experience-item" style="display:flex;align-items:center;margin-bottom:16px;padding:16px;background:#f8fafc;border-radius:8px;border-left:3px solid #2563eb;">
                      <img src="images/logos/hunyuan.png" alt="Hunyuan" style="width:40px;height:40px;object-fit:contain;margin-right:16px;border-radius:8px;">
                      <div style="flex:1;">
                        <div style="font-weight:600;color:#1e293b;">Tencent ‚Äî Hunyuan Video Team</div>
                        <div style="font-size:13px;color:#64748b;margin-top:4px;">Research Intern ¬∑ Text-Driven Video Action Generation</div>
                      </div>
                      <div style="font-size:13px;color:#64748b;white-space:nowrap;">Jun 2025 - Dec 2025</div>
                    </div>

                    <div class="experience-item" style="display:flex;align-items:center;margin-bottom:16px;padding:16px;background:#f8fafc;border-radius:8px;border-left:3px solid #2563eb;">
                      <img src="images/logos/kling.png" alt="Kling" style="width:40px;height:40px;object-fit:contain;margin-right:16px;border-radius:8px;">
                      <div style="flex:1;">
                        <div style="font-weight:600;color:#1e293b;">Kuaishou ‚Äî Kling GenAI Team</div>
                        <div style="font-size:13px;color:#64748b;margin-top:4px;">Research Intern ¬∑ Universal Video Editing for AIGC</div>
                      </div>
                      <div style="font-size:13px;color:#64748b;white-space:nowrap;">Jan 2025 - Jun 2025</div>
                    </div>

                    <div class="experience-item" style="display:flex;align-items:center;margin-bottom:16px;padding:16px;background:#f8fafc;border-radius:8px;border-left:3px solid #2563eb;">
                      <img src="images/logos/antgroup.png" alt="Ant Group" style="width:40px;height:40px;object-fit:contain;margin-right:16px;border-radius:8px;">
                      <div style="flex:1;">
                        <div style="font-weight:600;color:#1e293b;">Ant Group ‚Äî Ant Research</div>
                        <div style="font-size:13px;color:#64748b;margin-top:4px;">Research Intern ¬∑ Conversational Multi-Character Video Generation</div>
                      </div>
                      <div style="font-size:13px;color:#64748b;white-space:nowrap;">May 2024 - Dec 2024</div>
                    </div>

                    <div class="experience-item" style="display:flex;align-items:center;margin-bottom:16px;padding:16px;background:#f8fafc;border-radius:8px;border-left:3px solid #2563eb;">
                      <img src="images/logos/pika.png" alt="Pika Labs" style="width:40px;height:40px;object-fit:contain;margin-right:16px;border-radius:8px;">
                      <div style="flex:1;">
                        <div style="font-weight:600;color:#1e293b;">Pika Labs ‚Äî Feature Team</div>
                        <div style="font-size:13px;color:#64748b;margin-top:4px;">Research Intern ¬∑ Multimodal Video Generation</div>
                      </div>
                      <div style="font-size:13px;color:#64748b;white-space:nowrap;">Jan 2024 - May 2024</div>
                    </div>

                  </div>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading><i class="fas fa-book" style="margin-right:8px;color:#2563eb;"></i>Publications</heading>
                  <p style="margin-top:8px;font-size:13px;color:#6b7280;">* denotes equal contribution / co-first author</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- ==================== 2025 ==================== -->
              <tr>
                <td colspan="2" style="padding:20px 20px 10px 20px;">
                  <h3 style="color:#2563eb;border-bottom:2px solid #e5e7eb;padding-bottom:8px;margin:0;">2025</h3>
                </td>
              </tr>

              <!-- ===== 2025 Papers ===== -->

              <!-- 1. OmniSync (‰∏Ä‰Ωú) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/omnisync/omnisync.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="./OmniSync">
                    <papertitle>OmniSync: Towards Universal Lip Synchronization via Diffusion Transformers</papertitle>
                  </a>
                  <br>
                  <span class="venue-tag spotlight">NeurIPS 2025 Spotlight</span>
                  <br style="margin-bottom:8px;">
                  <strong>Ziqiao Peng</strong>, Jiwen Liu, Haoxian Zhang, Xiaoqiang Liu, Songlin Tang, Pengfei Wan, Di Zhang, Hongyan Liu, Jun He
                  <div class="paper-links">
                    <a href="./OmniSync"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/pdf/2505.21448"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 2. SyncTalk++ (‰∏Ä‰Ωú) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/synctalkpp/synctalkpp.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="./synctalk++">
                    <papertitle>SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting</papertitle>
                  </a>
                  <br>
                  <span class="venue-tag journal">IEEE TPAMI 2025</span>
                  <br style="margin-bottom:8px;">
                  <strong>Ziqiao Peng</strong>, Wentao Hu, Junyuan Ma, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Hui Tian, Jun He, Hongyan Liu, Zhaoxin Fan
                  <div class="paper-links">
                    <a href="./synctalk++"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2506.14742"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 3. DualTalk (‰∏Ä‰Ωú) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/dualtalk/dualtalk.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="./dualtalk">
                    <papertitle>DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations</papertitle>
                  </a>
                  <br>
                  <span class="venue-tag top">CVPR 2025</span>
                  <br style="margin-bottom:8px;">
                  <strong>Ziqiao Peng</strong>, Yanbo Fan, Haoyu Wu, Xuan Wang, Hongyan Liu, Jun He, Zhaoxin Fan
                  <div class="paper-links">
                    <a href="./dualtalk"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2505.18096"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 4. ActAvatar (‰∏Ä‰Ωú) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/actavatar/actavatar.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="./ActAvatar">
                    <papertitle>ActAvatar: Temporally-Aware Precise Action Control for Talking Avatars</papertitle>
                  </a>
                  <br>
                  <span class="venue-tag top">arXiv 2025</span>
                  <br style="margin-bottom:8px;">
                  <strong>Ziqiao Peng</strong>, Yi Chen, Yifeng Ma, Guozhen Zhang, Zhiyao Sun, Zixiang Zhou, Youliang Zhang, Zhengguang Zhou, Zhaoxin Fan, Hongyan Liu, Yuan Zhou, Qinglin Lu, Jun He
                  <div class="paper-links">
                    <a href="./ActAvatar"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2512.19546"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 5. MEGADance (ÂÖ±‰∏Ä) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/megadance/megadance.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2505.17543"><papertitle>MEGADance: Mixture-of-Experts Architecture for Genre-Aware 3D Dance Generation</papertitle></a>
                  <br>
                  <span class="venue-tag top">NeurIPS 2025</span>
                  <br style="margin-bottom:8px;">
                  Kaixing Yang*, Xulong Tang*, <strong>Ziqiao Peng</strong>*, Yuxuan Hu, Jun He, Hongyan Liu
                  <div class="paper-links">
                    <a href="https://arxiv.org/abs/2505.17543"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 6. GGTalker -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/ggtalker/ggtalker.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://vincenthu19.github.io/GGTalker/"><papertitle>GGTalker: Talking Head Synthesis with Generalizable Gaussian Priors and Identity-Specific Adaptation</papertitle></a>
                  <br>
                  <span class="venue-tag spotlight">ICCV 2025 Spotlight</span>
                  <br style="margin-bottom:8px;">
                  Wentao Hu, Shunkai Li, <strong>Ziqiao Peng</strong>, Haoxian Zhang, Fan Shi, Xiaoqiang Liu, Pengfei Wan, Di Zhang, Hui Tian
                  <div class="paper-links">
                    <a href="https://vincenthu19.github.io/GGTalker/"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2506.21513"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 7. UniAVGen -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/uniavgen/uniavgen.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://mcg-nju.github.io/UniAVGen/"><papertitle>UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions</papertitle></a>
                  <br>
                  <span class="venue-tag top">arXiv 2025</span>
                  <br style="margin-bottom:8px;">
                  Guozhen Zhang, Zixiang Zhou, Teng Hu, <strong>Ziqiao Peng</strong>, Youliang Zhang, Yi Chen, Yuan Zhou, Qinglin Lu, Limin Wang
                  <div class="paper-links">
                    <a href="https://mcg-nju.github.io/UniAVGen/"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2511.03334"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 8. StreamAvatar -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/streamavatar/streamavatar.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://streamavatar.github.io/"><papertitle>StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars</papertitle></a>
                  <br>
                  <span class="venue-tag top">arXiv 2025</span>
                  <br style="margin-bottom:8px;">
                  Zhiyao Sun*, <strong>Ziqiao Peng</strong>*, Yifeng Ma*, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu
                  <div class="paper-links">
                    <a href="https://streamavatar.github.io/"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2512.22065"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 9. Morpheus -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/morpheus/morpheus.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/ZZongzheng0918/Morpheus-Software"><papertitle>Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control</papertitle></a>
                  <br>
                  <span class="venue-tag top">RSS 2025</span>
                  <br style="margin-bottom:8px;">
                  Zongzheng Zhang, Jiawen Yang, <strong>Ziqiao Peng</strong>, Meng Yang, Jianzhu Ma, Lin Cheng, Huazhe Xu, Hang Zhao, Hao Zhao
                  <div class="paper-links">
                    <a href="https://github.com/ZZongzheng0918/Morpheus-Software"><i class="fab fa-github"></i> Code</a>
                    <a href="https://arxiv.org/abs/2507.16645"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 10. MACE-Dance (ÂÖ±‰∏Ä) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/macedance/macedance.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://macedance.github.io/"><papertitle>MACE-Dance: Motion-Appearance Cascaded Experts for Music-Driven Dance Video Generation</papertitle></a>
                  <br>
                  <span class="venue-tag top">arXiv 2025</span>
                  <br style="margin-bottom:8px;">
                  Kaixing Yang*, Jiashu Zhu*, Xulong Tang*, <strong>Ziqiao Peng</strong>*, Xiangyue Zhang, Puwei Wang, Jiahong Wu, Xiangxiang Chu, Hongyan Liu, Jun He
                  <div class="paper-links">
                    <a href="https://macedance.github.io/"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2512.18181"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 11. FlowerDance (ÂÖ±‰∏Ä) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/flowerdance/flowerdance.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://flowerdance25.github.io/"><papertitle>FlowerDance: MeanFlow for Efficient and Refined 3D Dance Generation</papertitle></a>
                  <br>
                  <span class="venue-tag top">arXiv 2025</span>
                  <br style="margin-bottom:8px;">
                  Kaixing Yang*, Xulong Tang*, <strong>Ziqiao Peng</strong>*, Xiangyue Zhang, Puwei Wang, Jun He, Hongyan Liu
                  <div class="paper-links">
                    <a href="https://flowerdance25.github.io/"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2511.21029"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- 12. CRUISE -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/cruise/cruise.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/SainingZhang/CRUISE"><papertitle>CRUISE: Cooperative Reconstruction and Editing in V2X Scenarios using Gaussian Splatting</papertitle></a>
                  <br>
                  <span class="venue-tag top">IROS 2025</span>
                  <br style="margin-bottom:8px;">
                  Haoran Xu, Saining Zhang, Peishuo Li, Baijun Ye, Xiaoxue Chen, Huan-ang Gao, Jv Zheng, Xiaowei Song, <strong>Ziqiao Peng</strong>, et al.
                  <div class="paper-links">
                    <a href="https://github.com/SainingZhang/CRUISE"><i class="fab fa-github"></i> Code</a>
                  </div>
                </td>
              </tr>

              <!-- 13. Meta-Face -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/metaface/metaface.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2408.09357"><papertitle>Meta-Learning Empowered Meta-Face: Personalized Speaking Style Adaptation for Audio-Driven 3D Talking Face Animation</papertitle></a>
                  <br>
                  <span class="venue-tag top">ICME 2025</span>
                  <br style="margin-bottom:8px;">
                  Xukun Zhou, Fengxin Li, <strong>Ziqiao Peng</strong>, Kejian Wu, Jun He, Biao Qin, Zhaoxin Fan, Hongyan Liu
                  <div class="paper-links">
                    <a href="https://arxiv.org/abs/2408.09357"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- ==================== 2024 ==================== -->
              <tr>
                <td colspan="2" style="padding:20px 20px 10px 20px;">
                  <h3 style="color:#2563eb;border-bottom:2px solid #e5e7eb;padding-bottom:8px;margin:0;">2024</h3>
                </td>
              </tr>

              <!-- SyncTalk (‰∏Ä‰Ωú) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/synctalk/synctalk.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="./synctalk">
                    <papertitle>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</papertitle>
                  </a>
                  <br>
                  <span class="venue-tag top">CVPR 2024</span>
                  <br style="margin-bottom:8px;">
                  <strong>Ziqiao Peng</strong>, Wentao Hu, Yue Shi, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Jun He, Hongyan Liu, Zhaoxin Fan
                  <div class="paper-links">
                    <a href="./synctalk"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2311.17590"><i class="fas fa-file-pdf"></i> arXiv</a>
                    <a href="https://github.com/ziqiaopeng/SyncTalk"><i class="fab fa-github"></i> Code</a>
                  </div>
                </td>
              </tr>

              <!-- VGG-Tex -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/vggtex/vggtex.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2409.09740"><papertitle>VGG-Tex: A Vivid Geometry-Guided Facial Texture Estimation Model for High Fidelity Monocular 3D Face Reconstruction</papertitle></a>
                  <br>
                  <span class="venue-tag top">arXiv 2024</span>
                  <br style="margin-bottom:8px;">
                  Haoyu Wu, <strong>Ziqiao Peng</strong>, Xukun Zhou, Yunfei Cheng, Jun He, Hongyan Liu, Zhaoxin Fan
                  <div class="paper-links">
                    <a href="https://arxiv.org/abs/2409.09740"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- ModelGrow -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/modelgrow/modelgrow.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2412.18966"><papertitle>ModelGrow: Continual Text-to-Video Pre-training with Model Expansion and Language Understanding Enhancement</papertitle></a>
                  <br>
                  <span class="venue-tag top">arXiv 2024</span>
                  <br style="margin-bottom:8px;">
                  Zhefan Rao, Liya Ji, Yazhou Xing, Runtao Liu, Zhaoyang Liu, Jiaxin Xie, <strong>Ziqiao Peng</strong>, Yingqing He, Qifeng Chen
                  <div class="paper-links">
                    <a href="https://arxiv.org/abs/2412.18966"><i class="fas fa-file-pdf"></i> arXiv</a>
                  </div>
                </td>
              </tr>

              <!-- ==================== 2023 ==================== -->
              <tr>
                <td colspan="2" style="padding:20px 20px 10px 20px;">
                  <h3 style="color:#2563eb;border-bottom:2px solid #e5e7eb;padding-bottom:8px;margin:0;">2023</h3>
                </td>
              </tr>

              <!-- SelfTalk (‰∏Ä‰Ωú) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/selftalk/selftalk.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="./selftalk">
                    <papertitle>SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces</papertitle>
                  </a>
                  <br>
                  <span class="venue-tag top">ACM MM 2023</span>
                  <br style="margin-bottom:8px;">
                  <strong>Ziqiao Peng</strong>, Yihao Luo, Yue Shi, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, Zhaoxin Fan
                  <div class="paper-links">
                    <a href="./selftalk"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2306.10799"><i class="fas fa-file-pdf"></i> arXiv</a>
                    <a href="https://github.com/psyai-net/SelfTalk_release"><i class="fab fa-github"></i> Code</a>
                  </div>
                </td>
              </tr>

              <!-- EmoTalk (‰∏Ä‰Ωú) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/emotalk/emotalk.png' style="width:200px;border-radius:8px;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="./emotalk">
                    <papertitle>EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation</papertitle>
                  </a>
                  <br>
                  <span class="venue-tag top">ICCV 2023</span>
                  <br style="margin-bottom:8px;">
                  <strong>Ziqiao Peng</strong>, Haoyu Wu, Zhenbo Song, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, Zhaoxin Fan
                  <div class="paper-links">
                    <a href="./emotalk"><i class="fas fa-globe"></i> Project</a>
                    <a href="https://arxiv.org/abs/2303.11089"><i class="fas fa-file-pdf"></i> arXiv</a>
                    <a href="https://github.com/psyai-net/EmoTalk_release"><i class="fab fa-github"></i> Code</a>
                  </div>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- More Publications Link -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;text-align:center;">
                  <a href="https://scholar.google.com/citations?user=gYTyZGYAAAAJ" target="_blank" style="font-size:15px;font-weight:500;">
                    <i class="fas fa-arrow-right"></i> View all publications on Google Scholar
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Service Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;">
                  <div class="service-box">
                    <heading><i class="fas fa-users" style="margin-right:8px;color:#2563eb;"></i>Academic Service</heading>
                    <div class="service-list">
                      <div style="margin-top:12px;">
                        <strong>Conference Reviewer:</strong> CVPR, NeurIPS, ICCV, ECCV, ACM MM, ICME, Eurographics
                      </div>
                      <div style="margin-top:8px;">
                        <strong>Journal Reviewer:</strong> IJCV, TIP, TMM, TOMM, IET Image Processing, IET Computer Vision
                      </div>
                    </div>
                  </div>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;">
                  <div class="footer">
                    <p>Last updated: February 2026</p>
                    <p style="margin-top:4px;">
                      Template credit to <a href="https://jonbarron.info">Jon Barron</a>
                    </p>
                  </div>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </tbody>
  </table>
<script>
function toggleWechatQR() {
  var popup = document.getElementById('wechat-qr-popup');
  if (popup.style.display === 'none') {
    popup.style.display = 'block';
  } else {
    popup.style.display = 'none';
  }
}

// Click outside to close
document.addEventListener('click', function(e) {
  var wrapper = document.querySelector('.wechat-wrapper');
  var popup = document.getElementById('wechat-qr-popup');
  if (wrapper && !wrapper.contains(e.target)) {
    popup.style.display = 'none';
  }
});
</script>
</body>
</html>
